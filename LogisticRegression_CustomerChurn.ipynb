{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression-CustomerChurn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagrmo11/logreg-customer-churn/blob/master/LogisticRegression_CustomerChurn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unx9yz5TNICj",
        "colab_type": "text"
      },
      "source": [
        "# Predicting Customer Churn with Logistic Regression in PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRVD0H1fZILj",
        "colab_type": "text"
      },
      "source": [
        "Install pysprk in enviornment. Does not come OOTB with Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqDF1wQiEyTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "4bdb2dac-f96d-4696-a8de-d38a96325322"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 122kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 40.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWBAc3HZRuY",
        "colab_type": "text"
      },
      "source": [
        "**Import pyspark libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i35MgFpyFBno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RnSM1SkZYeo",
        "colab_type": "text"
      },
      "source": [
        "**Create Spark session and read in CSV data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MzG69VtF2wX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName('logreg').getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmGUfueQF9Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = spark.read.csv('customer_churn.csv',inferSchema=True,header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb_nkkf4Zpf6",
        "colab_type": "text"
      },
      "source": [
        "**Explore Customer Churn data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VACUsD01GW-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a0120d51-345e-4338-d9f2-9e878d6d2e42"
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Names: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- Total_Purchase: double (nullable = true)\n",
            " |-- Account_Manager: integer (nullable = true)\n",
            " |-- Years: double (nullable = true)\n",
            " |-- Num_Sites: double (nullable = true)\n",
            " |-- Onboard_date: timestamp (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Company: string (nullable = true)\n",
            " |-- Churn: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZIYxAsJJHjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "d442f83f-cf63-41b3-affa-b47b22c4d38a"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
            "|              Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|\n",
            "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
            "|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|\n",
            "|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|\n",
            "|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|\n",
            "|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|\n",
            "|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|\n",
            "|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|2009-03-03 23:13:37|6187 Olson Mounta...|        Kelly-Warren|    1|\n",
            "|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|2016-12-05 03:35:43|4846 Savannah Roa...|   Reynolds-Sheppard|    1|\n",
            "|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|2006-03-09 14:50:20|25271 Roy Express...|          Singh-Cole|    1|\n",
            "|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|2011-09-29 05:47:23|3725 Caroline Str...|           Lopez PLC|    1|\n",
            "|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|2006-03-28 15:42:45|363 Sandra Lodge ...|       Reed-Martinez|    1|\n",
            "|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|2016-11-13 13:13:01|Unit 8120 Box 916...|Briggs, Lamb and ...|    1|\n",
            "|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|2015-05-28 12:14:03|Unit 1895 Box 094...|    Figueroa-Maynard|    1|\n",
            "|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|2011-02-16 08:10:47|897 Kelley Overpa...|     Abbott-Thompson|    1|\n",
            "|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|2012-11-22 05:35:03|11488 Weaver Cape...|Smith, Kim and Ma...|    1|\n",
            "|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|2015-03-28 02:13:44|1774 Peter Row Ap...|Snyder, Lee and M...|    1|\n",
            "|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|2015-07-22 08:38:40|45408 David Path ...|      Sanders-Pierce|    1|\n",
            "|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|2006-09-03 06:13:55|28216 Wright Moun...|Andrews, Adams an...|    1|\n",
            "|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|2006-10-22 04:42:38|Unit 4948 Box 481...|Morgan, Phillips ...|    1|\n",
            "|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|2015-10-07 00:27:10|69203 Crosby Divi...|      Villanueva LLC|    1|\n",
            "|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|2014-11-06 23:47:14|9569 Caldwell Cre...|Berry, Orr and Ca...|    1|\n",
            "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjGZ6-qOGbzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e136006b-697f-4f82-b91e-f686dd9bc0c3"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Names',\n",
              " 'Age',\n",
              " 'Total_Purchase',\n",
              " 'Account_Manager',\n",
              " 'Years',\n",
              " 'Num_Sites',\n",
              " 'Onboard_date',\n",
              " 'Location',\n",
              " 'Company',\n",
              " 'Churn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p482j3CjZweF",
        "colab_type": "text"
      },
      "source": [
        "**Use VectorAssembler to create vector of variables to be used to make the churn prediction. Transform the data to VectorAssembler format.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaB1CyoHHZEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assembler = VectorAssembler(inputCols=['Age',\n",
        " 'Total_Purchase',\n",
        " 'Account_Manager',\n",
        " 'Years',\n",
        " 'Num_Sites'],outputCol='features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUX5LKoHbB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = assembler.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9khJDMCYaVJw",
        "colab_type": "text"
      },
      "source": [
        "**Save the transformed dataframe after selecting the new features column and the churn column that you want to predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxV8icOqHm3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data = output.select('features','churn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b0RFLWJahjN",
        "colab_type": "text"
      },
      "source": [
        "**Split the data into test and training data sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlZAI1TiHqTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_churn,test_churn = final_data.randomSplit([0.7,0.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN9V0cn8apkf",
        "colab_type": "text"
      },
      "source": [
        "**Create a Logistic regression object using 'churn' as the column you want to predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgOU3m5DHu7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_churn = LogisticRegression(labelCol='churn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgrZxmhPa4Hv",
        "colab_type": "text"
      },
      "source": [
        "**Fit the logistic regression model on the training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGH0tZ1zHxwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fitted_churn_model = lr_churn.fit(train_churn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcRmTCvnbAPt",
        "colab_type": "text"
      },
      "source": [
        "**Check output of the fitted model and see the rawPrediction, probability, and prediction values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgyG7GlqH3gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sum = fitted_churn_model.summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cfZZnGbH7ab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "e9fcd9fb-8915-4e8c-e22f-fc10b55978df"
      },
      "source": [
        "training_sum.predictions.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|            features|churn|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|[25.0,9672.03,0.0...|  0.0|[4.53777904738992...|[0.98941607962991...|       0.0|\n",
            "|[26.0,8939.61,0.0...|  0.0|[6.26678604710152...|[0.99810527689047...|       0.0|\n",
            "|[27.0,8628.8,1.0,...|  0.0|[5.22570644675506...|[0.99465219244579...|       0.0|\n",
            "|[28.0,8670.98,0.0...|  0.0|[7.68680041323758...|[0.99954136650464...|       0.0|\n",
            "|[28.0,9090.43,1.0...|  0.0|[1.34824805349724...|[0.79384305879075...|       0.0|\n",
            "|[28.0,11128.95,1....|  0.0|[3.97140564433774...|[0.98150171333656...|       0.0|\n",
            "|[28.0,11204.23,0....|  0.0|[1.83611546300779...|[0.86248864202563...|       0.0|\n",
            "|[28.0,11245.38,0....|  0.0|[3.58375708387202...|[0.97297923467449...|       0.0|\n",
            "|[29.0,5900.78,1.0...|  0.0|[3.93243332794652...|[0.98078068912841...|       0.0|\n",
            "|[29.0,8688.17,1.0...|  1.0|[2.52458938687105...|[0.92584774962999...|       0.0|\n",
            "|[29.0,9378.24,0.0...|  0.0|[4.68404477291945...|[0.99084306615298...|       0.0|\n",
            "|[29.0,9617.59,0.0...|  0.0|[4.34207710598197...|[0.98715759493145...|       0.0|\n",
            "|[29.0,10203.18,1....|  0.0|[3.55749624567188...|[0.97228017764210...|       0.0|\n",
            "|[29.0,13240.01,1....|  0.0|[6.49410551818991...|[0.99848995632258...|       0.0|\n",
            "|[29.0,13255.05,1....|  0.0|[3.94750478745985...|[0.98106273600027...|       0.0|\n",
            "|[30.0,6744.87,0.0...|  0.0|[3.46494810772318...|[0.96967381196260...|       0.0|\n",
            "|[30.0,7960.64,1.0...|  1.0|[3.08487284316389...|[0.95626443408891...|       0.0|\n",
            "|[30.0,8403.78,1.0...|  0.0|[5.77710650303305...|[0.99691190036058...|       0.0|\n",
            "|[30.0,8874.83,0.0...|  0.0|[3.10787734654217...|[0.95721651093934...|       0.0|\n",
            "|[30.0,10183.98,1....|  0.0|[2.72743814497408...|[0.93862642248255...|       0.0|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTmNGGH9bxTG",
        "colab_type": "text"
      },
      "source": [
        "**Now use the fitted model on the test data and evalaute the predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdH0Laf0JRcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_and_labels = fitted_churn_model.evaluate(test_churn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky3CKFXNJUnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "eaff3b62-169e-49ad-db0f-33d1136844db"
      },
      "source": [
        "pred_and_labels.predictions.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|            features|churn|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|[22.0,11254.38,1....|    0|[4.35687913401306...|[0.98734390047568...|       0.0|\n",
            "|[26.0,8787.39,1.0...|    1|[0.46981080864297...|[0.61533897635686...|       0.0|\n",
            "|[29.0,11274.46,1....|    0|[4.32041624637542...|[0.98688007222813...|       0.0|\n",
            "|[29.0,12711.15,0....|    0|[5.21705004738516...|[0.99460594953352...|       0.0|\n",
            "|[30.0,8677.28,1.0...|    0|[3.89121228685363...|[0.97998807950078...|       0.0|\n",
            "|[30.0,10960.52,1....|    0|[2.20472541645675...|[0.90067305298035...|       0.0|\n",
            "|[30.0,12788.37,0....|    0|[2.46012346675768...|[0.92129861555817...|       0.0|\n",
            "|[31.0,9574.89,0.0...|    0|[3.15609104287833...|[0.95914805611776...|       0.0|\n",
            "|[31.0,12264.68,1....|    0|[3.31660205003806...|[0.96499398789653...|       0.0|\n",
            "|[32.0,7896.65,0.0...|    0|[3.32251422319835...|[0.96519315648181...|       0.0|\n",
            "|[32.0,9036.27,0.0...|    0|[-0.2930669849090...|[0.42725318473055...|       1.0|\n",
            "|[32.0,9472.72,1.0...|    0|[3.92004576632558...|[0.98054578847777...|       0.0|\n",
            "|[32.0,11540.86,0....|    0|[6.74132465929177...|[0.99882031171888...|       0.0|\n",
            "|[33.0,4711.89,0.0...|    0|[5.88433674434967...|[0.99722503063388...|       0.0|\n",
            "|[33.0,5738.82,0.0...|    0|[4.24800433150652...|[0.98590867448196...|       0.0|\n",
            "|[33.0,7720.61,1.0...|    0|[1.62399164137124...|[0.83534489051623...|       0.0|\n",
            "|[33.0,8556.73,0.0...|    0|[3.77002832075134...|[0.97746798429739...|       0.0|\n",
            "|[33.0,11370.28,1....|    0|[6.49797807691992...|[0.99849578396792...|       0.0|\n",
            "|[33.0,12638.51,1....|    0|[3.71015982690757...|[0.97611103776156...|       0.0|\n",
            "|[34.0,6461.86,1.0...|    0|[4.21454035840616...|[0.98543612781579...|       0.0|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqkNcDFUb83q",
        "colab_type": "text"
      },
      "source": [
        "**Use the BinaryClssificationEvaluator to check how good your model worked at making correct predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj-OxJeKJXz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "churn_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='churn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12d6BgdgYfsZ",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation of AUC not working in Colab**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InapDKudJd5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1327
        },
        "outputId": "850136b1-0369-487d-a7d4-4246ebd0c020"
      },
      "source": [
        "auc = churn_eval.evaluate(pred_and_labels.predictions)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1018.evaluate.\n: java.lang.IllegalArgumentException: Unsupported class file major version 55\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237)\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500)\n\tat org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175)\n\tat org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306)\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2326)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2100)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.x$4$lzycompute(BinaryClassificationMetrics.scala:192)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.x$4(BinaryClassificationMetrics.scala:146)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.confusions$lzycompute(BinaryClassificationMetrics.scala:148)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.confusions(BinaryClassificationMetrics.scala:148)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.createCurve(BinaryClassificationMetrics.scala:223)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.roc(BinaryClassificationMetrics.scala:86)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.areaUnderROC(BinaryClassificationMetrics.scala:97)\n\tat org.apache.spark.ml.evaluation.BinaryClassificationEvaluator.evaluate(BinaryClassificationEvaluator.scala:87)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-7f74fd8631b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchurn_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_and_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Unsupported class file major version 55'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UCkg657dcQ2",
        "colab_type": "text"
      },
      "source": [
        "**Fit the logistic regression model on at the entire data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GEKDM-pKEwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_lr_model = lr_churn.fit(final_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvleEELLdrUn",
        "colab_type": "text"
      },
      "source": [
        "**Import and explore new unlabeled customer dataset - no churn column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoZxzun_KKQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_customers = spark.read.csv('new_customers.csv',inferSchema=True,header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0aQ0twgKT0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "88f22292-2142-4014-de19-ac0008c7890a"
      },
      "source": [
        "new_customers.printSchema()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Names: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- Total_Purchase: double (nullable = true)\n",
            " |-- Account_Manager: integer (nullable = true)\n",
            " |-- Years: double (nullable = true)\n",
            " |-- Num_Sites: double (nullable = true)\n",
            " |-- Onboard_date: timestamp (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Company: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhI4SNLSd4JS",
        "colab_type": "text"
      },
      "source": [
        "**Apply same VectorAssembler transformation to create features column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fquNPVApKVS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_new_customers = assembler.transform(new_customers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bof2RS2bKZPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e050497f-a5a0-4b52-d9d3-35233942c30e"
      },
      "source": [
        "test_new_customers.printSchema()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Names: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- Total_Purchase: double (nullable = true)\n",
            " |-- Account_Manager: integer (nullable = true)\n",
            " |-- Years: double (nullable = true)\n",
            " |-- Num_Sites: double (nullable = true)\n",
            " |-- Onboard_date: timestamp (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Company: string (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs8caE5ngHiY",
        "colab_type": "text"
      },
      "source": [
        "**Apply model to newly transformed unlabeled customer data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x03FOiwQKb9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_results = final_lr_model.transform(test_new_customers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbMjhwJWgSZN",
        "colab_type": "text"
      },
      "source": [
        "**See churn predictions for each company based on historical data.\n",
        "0 = Will not churn\n",
        "1= Will churn**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPXC24WzK-Yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a4d2abd6-5b35-4135-f272-d5d29fbc2e41"
      },
      "source": [
        "final_results.select('Company','prediction').show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+----------+\n",
            "|         Company|prediction|\n",
            "+----------------+----------+\n",
            "|        King Ltd|       0.0|\n",
            "|   Cannon-Benson|       1.0|\n",
            "|Barron-Robertson|       1.0|\n",
            "|   Sexton-Golden|       1.0|\n",
            "|        Wood LLC|       0.0|\n",
            "|   Parks-Robbins|       1.0|\n",
            "+----------------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}